# LSTM-Based-Speech-Recognition
Continuous speech recognition applications that involve secure electronic device control requires a robust, stand-alone system and less dependence on server-based processing. Acoustic modeling, state modeling and end-end modeling are some of the categories of existing systems. Long Short-Term Memory (LSTM) networks exploit self-learned temporal context and possess unique modelling capabilities and are a natural  choice for developing such systems. This paper involves the design of a LSTM system that directly processes
speech signal information, learns directly from acoustic vectors and provides accurate classification of test signals. The entire process involves 2 stages. In the first stage, acoustic vectors are obtained from training signals and processed by the LSTM network along with categorical information. The network learns from these vectors. In the second stage, the trained network classifies the test signal to generate the recognized text. A set of 11 sentences are provided as test signals to the network with a Word Error Rate (WER) of 21.05. The results show there is a decrease in WER of 11.9% from the baseline Gaussian Mixture Model â€“ Hidden Markov Model (GMM-HMM) system and 6.8% from the LSTM-HMM system. The system performs end-to-end processing by directly capturing train and test signals and is a suitable choice for implementation as a dedicated hardware in electronic devices
